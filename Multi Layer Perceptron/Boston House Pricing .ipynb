{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston House Price Prediction\n",
    "\n",
    "The dataset describes 13 numerical properties of houses in Boston suburbs and is concerned with modeling the price of houses in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem. Input attributes include things like crime rate, proportion of nonretail business acres, chemical concentrations and more.\n",
    "\n",
    "Reasonable performance for models evaluated using Mean Squared Error (MSE) are around 20 in squared thousands of dollars (or $4,500 if you take the square root). This is a nice target to aim for with our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 80.14  (35.58) MSE\n"
     ]
    }
   ],
   "source": [
    "#develop a baseline neural net model\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#load dataset\n",
    "dataframe=pandas.read_csv('housing.data',delim_whitespace=True,header=None)\n",
    "dataset=dataframe.values\n",
    "#split inot input(X) nad output (y) variables\n",
    "X=dataset[:,0:13]\n",
    "Y=dataset[:,13]\n",
    "\n",
    "#define a base model\n",
    "def baseline_model():\n",
    "    #create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(13,input_dim=13,init='normal',activation='relu'))\n",
    "    model.add(Dense(1,init='normal'))\n",
    "    #compile model\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "#fix random seed for reproductibility\n",
    "seed=43\n",
    "numpy.random.seed(seed)\n",
    "#evaluate model woth standardized dataset\n",
    "estimator=KerasRegressor(build_fn=baseline_model,nb_epoch=100,batch_size=5,verbose=0)\n",
    "\n",
    "\n",
    "kfold=KFold(10,random_state=seed)\n",
    "results=cross_val_score(estimator,X,Y,cv=kfold)\n",
    "print(\"Results: %.2f  (%.2f) MSE\" % (results.mean(),results.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the Standardized Dataset\n",
    "An important concern with the Boston house price dataset is that the input attributes all vary in their scales because they measure different quantities.\n",
    "\n",
    "It is almost always good practice to prepare your data before modeling it using a neural network model.\n",
    "\n",
    "Continuing on from the above baseline model, we can re-evaluate the same model using a standardized version of the input dataset.\n",
    "\n",
    "We can use scikit-learnâ€™s Pipeline framework to perform the standardization during the model evaluation process, within each fold of the cross validation. This ensures that there is no data leakage from each testset cross validation fold into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 691.05  (187.29) MSE\n"
     ]
    }
   ],
   "source": [
    "#evaluate model with standardized dataset\n",
    "estimators=[]\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp',KerasRegressor(build_fn=baseline_model,nb_epoch=50,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(10,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,Y,cv=kfold)\n",
    "print (\"Standardized: %.2f  (%.2f) MSE\" %(results.mean(),results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a deeper Network Topology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 52.78 (22.53) MSE\n"
     ]
    }
   ],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(13, input_dim=13, init='normal', activation='relu'))\n",
    "\tmodel.add(Dense(6, init='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, init='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "#estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp1', KerasRegressor(build_fn=larger_model, nb_epoch=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
