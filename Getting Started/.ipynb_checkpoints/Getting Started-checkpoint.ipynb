{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle,gzip,numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([5, 0, 4, ..., 8, 4, 8]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "f=gzip.open('mnist.pkl.gz','rb')\n",
    "train_set,valid_set,test_set=cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How to store your data and how to access a minibatch\n",
    "\n",
    "def shared_dataset(data_xy):\n",
    "    \"\"\"Function that loads the dataset into shared variables\n",
    "    \n",
    "    The reason we store our dataset in shared variables is to allow\n",
    "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    is needed (the default behaviour if the data is not in a shared\n",
    "    variable) would lead to a large decrease in performance.    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_x,data_y=data_xy\n",
    "    shared_x=theano.shared(numpy.asarray(data_x,dtype=theano.config.floatX))\n",
    "    shared_y=theano.shared(numpy.asarray(data_y,dtype=theano.config.floatX))\n",
    "    \n",
    "    \"\"\" When storing data on the GPU it has to be stored as floats\n",
    "    # therefore we will store the labels as ‘‘floatX‘‘ as well\n",
    "    # (‘‘shared_y‘‘ does exactly that). But during our computations\n",
    "    # we need them as ints (we use labels as index, and if they are\n",
    "    # floats it doesn’t make sense) therefore instead of returning\n",
    "    # ‘‘shared_y‘‘ we will have to cast it to int. This little hack\n",
    "    # lets us get around this issue\n",
    "    \"\"\"\n",
    "    \n",
    "    return shared_x,T.cast(shared_y,'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_x,test_set_y=shared_dataset(test_set)\n",
    "valid_set_x,valid_set_y=shared_dataset(valid_set)\n",
    "train_set_x,train_set_y=shared_dataset(train_set)\n",
    "\n",
    "batch_size=500  #size of minibatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accessing the third minibatch of the training set\n",
    "\n",
    "data=train_set_x[2*batch_size:3*batch_size]\n",
    "label=train_set_y[2*batch_size:3*batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Conventions\n",
    "\n",
    "• W : upper-case symbols refer to a matrix unless specified otherwise\n",
    "\n",
    "• W ij : element at i-th row and j-th column of matrix W\n",
    "\n",
    "• W i· , W i : vector, i-th row of matrix W\n",
    "\n",
    "• W ·j : vector, j-th column of matrix W\n",
    "\n",
    "• b: lower-case symbols refer to a vector unless specified otherwise\n",
    "\n",
    "• b i : i-th element of vector b\n",
    "\n",
    "## List of Symbols and acronyms\n",
    "\n",
    "• D: number of input dimensions.\n",
    "  (i)\n",
    "• D h : number of hidden units in the i-th layer.\n",
    "\n",
    "• f θ (x), f (x): classification function associated with a model P(Y |x, θ), defined as argmax k P (Y =k|x, θ). Note that we will often drop the θ subscript.\n",
    "\n",
    "• L: number of labels.\n",
    "\n",
    "• L(θ, D): log-likelihood D of the model defined by parameters θ.\n",
    "\n",
    "• (θ, D) empirical loss of the prediction function f parameterized by θ on data set D.\n",
    "\n",
    "• NLL: negative log-likelihood\n",
    "\n",
    "• θ: set of all parameters for a given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Classifier\n",
    "\n",
    "### Zero-One Loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_y_given_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2cd4c96da00e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# symbolic expression has to be compiled into a Theano function (see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# the Theano tutorial for more details)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mzero_one_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_y_given_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p_y_given_x' is not defined"
     ]
    }
   ],
   "source": [
    "# zero_one_loss is a Theano variable representing a symbolic\n",
    "# expression of the zero one loss ; to get the actual value this\n",
    "# symbolic expression has to be compiled into a Theano function (see\n",
    "# the Theano tutorial for more details)\n",
    "zero_one_loss = T.sum(T.neq(T.argmax(p_y_given_x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Log-Likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_y_given_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-44250c1114be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNLL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_y_given_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p_y_given_x' is not defined"
     ]
    }
   ],
   "source": [
    "NLL = -T.sum(T.log(p_y_given_x)[T.arange(y.shape[0]), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
